{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Word Embedding? \n",
    "\n",
    "## \"word embedding\" or \"word vector\"\n",
    "\n",
    "## \"詞嵌入\" or \"詞向量\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Word Embedding is a type of word representation that allows words with similar meaning to be understood by machine learning algorithms. \n",
    "\n",
    "Technically speaking, it is a mapping of words into vectors of real numbers using the neural network, probabilistic model, or dimension reduction on word co-occurrence matrix. \n",
    "\n",
    "It is language modeling and feature learning technique. Word embedding is a way to perform mapping using a neural network. \n",
    "\n",
    "There are various word embedding models available such as word2vec (Google), Glove (Stanford) and fastext (Facebook).\n",
    "\n",
    "Reference:\n",
    "https://www.guru99.com/word-embedding-word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://adriancolyer.files.wordpress.com/2016/04/word2vec-king-queen-vectors.png?w=656&zoom=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity between two vectors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 計算兩兩圖形特徵之相似度  \n",
    "\n",
    "cosine值 介於-1 ~ 1 之間  \n",
    "\n",
    "cosine(0) = 1   0度表示最相近，所以cosine值越接近1 越相似!!\n",
    "\n",
    "cosine(0) = 0   表是兩者不相似\n",
    "\n",
    "cosine(0) = -1  表示兩者意見相左 相反 \n",
    "\n",
    "\n",
    "\n",
    "Since the cos(θ) value is in the range [−1,1] :\n",
    "\n",
    "−1 value will indicate strongly opposite vectors\n",
    "0 independent (orthogonal) vectors\n",
    "1 similar (positive co-linear) vectors. Intermediate values are used to assess the degree of similarity.\n",
    "Example : Let two user U1 and U2, and sim(U1,U2) the similarity between these two users according to their taste for movies:\n",
    "\n",
    "sim(U1,U2)=1 if the two users have exactly the same taste (or if U1=U2)\n",
    "sim(U1,U2)=0 if we do not find any correlation between the two users, e.g. if they have not seen any common movies\n",
    "sim(U1,U2)=−1 if users have opposed tastes, e.g. if they rated the same movies in an opposite way\n",
    "\n",
    "https://stats.stackexchange.com/questions/198810/interpreting-negative-cosine-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://pic3.zhimg.com/v2-fc17fd8286802d0ad2ff45e4068cc489_1200x500.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two vectors of attributes, A and B, the cosine similarity, cos(θ), is represented using a dot product and magnitude as\n",
    "\n",
    "![](https://i.stack.imgur.com/Qmq2w.png)\n",
    "\n",
    "where Ai and Bi are components of vector A and B respectively.\n",
    "\n",
    "The resulting similarity ranges from −1 meaning exactly opposite, to 1 meaning exactly the same, with 0 indicating orthogonality or decorrelation, while in-between values indicate intermediate similarity or dissimilarity.\n",
    "\n",
    "Reference:\n",
    "https://www.wikiwand.com/en/Cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning with word vectors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The vectors are very good at answering analogy questions of the form a is to b as c is to ?. For example, man is to woman as uncle is to ? (aunt) using a simple vector offset method based on cosine distance.\n",
    "\n",
    "For example, here are vector offsets for three word pairs illustrating the gender relation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://adriancolyer.files.wordpress.com/2016/04/word2vec-gender-relation.png?w=596&zoom=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://adriancolyer.files.wordpress.com/2016/04/word2vec-plural-relation.png?w=610&zoom=2)\n",
    "\n",
    "Reference: https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Word2vec is a group of related models that are used to produce word embeddings. \n",
    "\n",
    "These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. \n",
    "\n",
    "Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. \n",
    "\n",
    "Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located close to one another in the space.\n",
    "\n",
    "Word2vec was created and published in 2013 by a team of researchers led by Tomas Mikolov at Google and patented.\n",
    "\n",
    "Reference:\n",
    "https://www.wikiwand.com/en/Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-66808-6_16/MediaObjects/456304_1_En_16_Fig3_HTML.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1280/0*EGByb1WV6Uz8vjST.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/664/1*TRsyvDhPB6_KCimEk-2kWQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow vs. Deep learning\n",
    "\n",
    "![](https://www.guru99.com/images/1/111318_0826_WordEmbeddi1.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "original paper:\n",
    "https://arxiv.org/pdf/1301.3781.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pbs.twimg.com/media/DXrYK-bXUAAhctK?format=jpg&name=large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Doc2vec has the following vectors\n",
    "(1)\n",
    "word vectors\n",
    "\n",
    "(2)\n",
    "paragraph (document) vectors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The concept that Mikilov and Le have used was simple, yet clever: they have used the word2vec model, and added another vector (Paragraph ID below), like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-66808-6_16/MediaObjects/456304_1_En_16_Fig4_HTML.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed Memory version of Paragraph Vector (PV-DM)\n",
    "\n",
    "![](https://miro.medium.com/max/972/0*x-gtU4UlO8FAsRvL.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed Bag of Words version of Paragraph Vector (PV-DBOW)\n",
    "\n",
    "![](https://miro.medium.com/max/880/0*NtIsrbd4VQzUKVKr.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "original paper:\n",
    "https://cs.stanford.edu/~quocle/paragraph_vector.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.researchgate.net/profile/Le-Lu-9/publication/303376372/figure/fig6/AS:668376489816091@1536364781736/Example-words-embedded-in-the-vector-space-using-word-to-vector-modeling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim doc2vec package"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://radimrehurek.com/gensim/index.html\n",
    "\n",
    "\n",
    "https://radimrehurek.com/gensim/models/doc2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://radimrehurek.com/gensim/_static/images/gensim.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install package\n",
    "# !pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data with TaggedDocument format"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We need to prepare the following two things:\n",
    "\n",
    "(1) tokenized word list for a document  \n",
    "\n",
    "(2) tag id for a document\n",
    "\n",
    "Each TaggedDocument is as the following:\n",
    "\n",
    "TaggedDocument(words=['well', 'done!'], tags=['doc_0'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Notice that we must use tags with string format, or we cannot query by using item_id (tag) from the word2vec model.\n",
    "We must use the item_id (string format) as the document tag. A string document tag is equivalent of a vocaburay object in the word2vec model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents \n",
    "train_docs = [\n",
    "    'machine learning',\n",
    "    'deep learning',\n",
    "    'machine learning deep learning',\n",
    "    'good work',\n",
    "    'good job',\n",
    "    'good work good job'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i, text in enumerate( train_docs ):\n",
    "    # prepare tokenized word list\n",
    "    words = text.lower().split()\n",
    "    # prepare document number\n",
    "    tags = ['doc_{}'.format(i)]\n",
    "    # prepare document format for Doc2vec training\n",
    "    documents.append(TaggedDocument(words, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['machine', 'learning'], tags=['doc_0']),\n",
       " TaggedDocument(words=['deep', 'learning'], tags=['doc_1']),\n",
       " TaggedDocument(words=['machine', 'learning', 'deep', 'learning'], tags=['doc_2']),\n",
       " TaggedDocument(words=['good', 'work'], tags=['doc_3']),\n",
       " TaggedDocument(words=['good', 'job'], tags=['doc_4']),\n",
       " TaggedDocument(words=['good', 'work', 'good', 'job'], tags=['doc_5'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents2 = [TaggedDocument(doc, [\"doc_{}\".format(i)]) for i, doc in enumerate(common_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['human', 'interface', 'computer'], tags=['doc_0']),\n",
       " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=['doc_1']),\n",
       " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=['doc_2']),\n",
       " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=['doc_3']),\n",
       " TaggedDocument(words=['user', 'response', 'time'], tags=['doc_4']),\n",
       " TaggedDocument(words=['trees'], tags=['doc_5']),\n",
       " TaggedDocument(words=['graph', 'trees'], tags=['doc_6']),\n",
       " TaggedDocument(words=['graph', 'minors', 'trees'], tags=['doc_7']),\n",
       " TaggedDocument(words=['graph', 'minors', 'survey'], tags=['doc_8'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 100 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train model\n",
    "# epochs = 5 \n",
    "model = Doc2Vec(documents, vector_size = 2, window = 5, min_count = 1, workers = 4, epochs = 7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some important parameters:\n",
    "\n",
    "class gensim.models.doc2vec.Doc2Vec(documents=None, size=300, alpha=0.025, window=8, min_count=5, max_vocab_size=None, sample=0, seed=1, workers=1, min_alpha=0.0001, dm=1, hs=1, negative=0, dbow_words=0, dm_mean=0, dm_concat=0, dm_tag_count=1, docvecs=None, docvecs_mapfile=None, comment=None, trim_rule=None, **kwargs)\n",
    "\n",
    "\n",
    "iter?\n",
    "------------------------------------\n",
    "iter = 10 is better than iter=5 ?\n",
    "\n",
    "A better training strategy:\n",
    "for epoch in range(10):\n",
    "    model.train(sentences)\n",
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The number of mdoel file will be one or there, depending on the size of model.\n",
    "\n",
    "Models with larger internal vector-arrays can't be saved via Python 'pickle' to a single file, so beyond a certain threshold, the gensim save() method will store subsidiary arrays in separate files, using the more-efficient raw format of numpy arrays (.npy format).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./simple_doc2vec.model\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sometimes, you will need to save the model with the word2vec_format. With the model of word2vec_format, some functions cannot be used, such as  .infer_vector(). However, this function is very important to us. So we don't use save_word2vec_format() here.\n",
    "\n",
    "Save to word2vec_format model:\n",
    "model.save_word2vec_format(\"my_trained_d2v/simple_w2v_format\")\n",
    "\n",
    "Load the model\n",
    "model3 = Doc2Vec.load_word2vec_format(\"my_trained_d2v/simple_w2v_format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Doc2vec model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Gensim should be the same version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model = Doc2Vec.load(\"./simple_doc2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word vector and document vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'learning', 'job', 'work', 'deep', 'machine']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02681136,  0.01182157],\n",
       "       [ 0.25516748,  0.45046365],\n",
       "       [-0.4651475 , -0.35584044],\n",
       "       [ 0.32294363,  0.4486494 ],\n",
       "       [-0.2507714 , -0.18816859],\n",
       "       [ 0.36902523, -0.07667357]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get vector for a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\1097064260.py:1: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  model.wv.word_vec('work')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.32294363, 0.4486494 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.word_vec('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\4100944095.py:1: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  model.wv.word_vec('good')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02681136,  0.01182157], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.word_vec('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if input word is not in the wordindex, error will arise\n",
    "# model.wv.word_vec('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\4164750585.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.index_to_key\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['doc_0', 'doc_1', 'doc_2', 'doc_3', 'doc_4', 'doc_5']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\2727991311.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.26154077, -0.29895633],\n",
       "       [-0.49411625,  0.42764473],\n",
       "       [ 0.17838673,  0.01315755],\n",
       "       [-0.493913  , -0.25835383],\n",
       "       [-0.48611858,  0.10064545],\n",
       "       [ 0.14173782,  0.23219481]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vector for a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\1231349363.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs['doc_0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.26154077, -0.29895633], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs['doc_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\651019407.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs['doc_1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.49411625,  0.42764473], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs['doc_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw 2D vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_labels(low_dim_embs, labels, filename = 'tsne.png'):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    # plt.figure(figsize=(10, 8))  # in inches (larger graph)\n",
    "    plt.figure(figsize=(8, 6))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                 xy = (x, y),\n",
    "                 xytext = (5, 2),\n",
    "                 textcoords = 'offset points',\n",
    "                 ha = 'right',\n",
    "                 va = 'bottom')\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tsne plot \n",
    "tsne = TSNE(perplexity = 30.0, n_components = 2, init = 'pca', n_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# It will take time\n",
    "two_dim_vectors = tsne.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting and saving the fig \n",
    "plot_with_labels(two_dim_vectors, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\1045885723.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  words = model.docvecs.index_to_key\n"
     ]
    }
   ],
   "source": [
    "words = model.docvecs.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\3799227662.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  vectors = model.docvecs.vectors\n"
     ]
    }
   ],
   "source": [
    "vectors = model.docvecs.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# It will take time\n",
    "two_dim_vectors = tsne.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting and saving the fig \n",
    "plot_with_labels(two_dim_vectors, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most similar words"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "most_similar(positive=None, negative=None, topn=10, restrict_vocab=None, indexer=None)\n",
    "Find the top-N most similar words. Positive words contribute positively towards the similarity, negative words negatively.\n",
    "\n",
    "This method computes cosine similarity between a simple mean of the projection weight vectors of the given words and the vectors for each word in the model. The method corresponds to the word-analogy and distance scripts in the original word2vec implementation.\n",
    "\n",
    "Parameters\n",
    "positive (list of str, optional) – List of words that contribute positively.\n",
    "\n",
    "negative (list of str, optional) – List of words that contribute negatively.\n",
    "\n",
    "topn (int or None, optional) – Number of top-N similar words to return, when topn is int. When topn is None, then similarities for all words are returned.\n",
    "\n",
    "restrict_vocab (int, optional) – Optional integer which limits the range of vectors which are searched for most-similar values. For example, restrict_vocab=10000 would only check the first 10000 word vectors in the vocabulary order. (This may be meaningful if you’ve sorted the vocabulary by descending frequency.)\n",
    "\n",
    "Returns\n",
    "When topn is int, a sequence of (word, similarity) is returned. When topn is None, then similarities for all words are returned as a one-dimensional numpy array with the size of the vocabulary.\n",
    "\n",
    "Return type\n",
    "list of (str, float) or numpy.array\n",
    "\n",
    "https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity from -1 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.stack.imgur.com/5hD3g.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cosine similarity can be interpreted as the dot product. \n",
    "\n",
    "Thus, if two words have 0 cosine similarity, they are completely orthogonal, meaning they have two different \"meanings\" and are completely unrelated. \n",
    "\n",
    "Whereas a negative similarity means the two words are related in component, but in an opposite (or negative) fashion."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Since the cos(θ) value is in the range [−1,1] :\n",
    "\n",
    "−1 value will indicate strongly opposite vectors\n",
    "\n",
    "0 independent (orthogonal) vectors\n",
    "\n",
    "1 similar (positive co-linear) vectors. Intermediate values are used to assess the degree of similarity.\n",
    "\n",
    "Example : Let two user U1 and U2, and sim(U1,U2) the similarity between these two users according to their taste for movies:\n",
    "\n",
    "sim(U1,U2)=1 if the two users have exactly the same taste (or if U1=U2)\n",
    "\n",
    "sim(U1,U2)=0 if we do not find any correlation between the two users, e.g. if they have not seen any common movies\n",
    "\n",
    "sim(U1,U2)=−1 if users have opposed tastes, e.g. if they rated the same movies in an opposite way\n",
    "\n",
    "Reference:\n",
    "https://stats.stackexchange.com/questions/198810/interpreting-negative-cosine-similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('work', 0.9941185116767883),\n",
       " ('machine', 0.305563747882843),\n",
       " ('good', -0.09994741529226303)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['learning'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30556372"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity score\n",
    "model.wv.similarity('machine','learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deep', 0.48973965644836426),\n",
       " ('job', 0.4816059172153473),\n",
       " ('learning', -0.09994742274284363)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['good'], topn = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4816059"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('good','job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.97794414"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the two words are not similar, because the similarity socre is small. \n",
    "model.wv.similarity('good','machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most similar words based on a set of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 0.953560471534729),\n",
       " ('job', 0.19527064263820648),\n",
       " ('work', 0.0971737876534462)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['deep','learning'], topn = 3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# if word 'data' is not in vocabulary, error will arise\n",
    "# In this case, we should use infer_vector() in the next section\n",
    "# model.wv.most_similar(['deep','learning','data'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive and nagative similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deep', 0.8653990626335144),\n",
       " ('learning', -0.5925893783569336),\n",
       " ('work', -0.6763386130332947)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['good', 'job'], topn = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deep', 0.9299444556236267), ('work', -0.7777612805366516)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find points in the vector space that are as close as possible to the positive vectors\n",
    "# and as far away as possible from the negative words\n",
    "model.wv.most_similar(positive=['good', 'job'], negative = ['machine', 'learning'], topn = 3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It's not quite \"find points in the vector space that are as close as possible to the positive vectors and as far away as possible from the negative ones\". Rather, as described in the original word2vec papers, it performs vector arithmetic: adding the positive vectors, subtracting the negative, then from that resulting position, listing the known-vectors closest to that angle.\n",
    "\n",
    "That is sufficient to solve man : king :: woman :: ?-style analogies, via a call like:\n",
    "\n",
    "sims = wordvecs.most_similar(positive=['king', 'woman'], \n",
    "                             negative=['man'])\n",
    "(You can think of this as, \"start at 'king'-vector, add 'woman'-vector, subtract 'man'-vector, from where you wind up, report ranked word-vectors closest to that point.\")\n",
    "\n",
    "Reference:\n",
    "https://stackoverflow.com/questions/54580260/understanding-gensim-word2vecs-most-similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer vector of keywords from the word2vec model (vector space) 輸入一個詞或多個詞，推論計算代表這一組詞的向量"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "infer_vector(doc_words, alpha=None, min_alpha=None, epochs=None, steps=None)\n",
    "\n",
    "Infer a vector for given post-bulk training document.\n",
    "\n",
    "Notes\n",
    "\n",
    "Subsequent calls to this function may infer different representations for the same document. For a more stable representation, increase the number of steps to assert a stricket convergence.\n",
    "\n",
    "Parameters\n",
    "doc_words (list of str) – A document for which the vector representation will be inferred.\n",
    "\n",
    "alpha (float, optional) – The initial learning rate. If unspecified, value from model initialization will be reused.\n",
    "\n",
    "min_alpha (float, optional) – Learning rate will linearly drop to min_alpha over all inference epochs. If unspecified, value from model initialization will be reused.\n",
    "\n",
    "epochs (int, optional) – Number of times to train the new document. Larger values take more time, but may improve quality and run-to-run stability of inferred vectors. If unspecified, the epochs value from model initialization will be reused.\n",
    "\n",
    "steps (int, optional, deprecated) – Previous name for epochs, still available for now for backward compatibility: if epochs is unspecified but steps is, the steps value will be used.\n",
    "\n",
    "Returns\n",
    "The inferred paragraph vector for the new document.\n",
    "\n",
    "Return type\n",
    "np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11741042, -0.19451982], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# infer vector of keywords from the word2vec model (vector space)\n",
    "model.infer_vector(['machine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\629783342.py:2: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  model.wv.word_vec('machine')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.36902523, -0.07667357], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "model.wv.word_vec('machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18918513, -0.01227807], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given a set of words in a document, infer_vector() infers a new vector  \n",
    "model.infer_vector( ['machine', 'learning'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if some words are not in the word index, \n",
    "# infer_vecter() can deal with this, and it will not throw exception\n",
    "# for example:  ['machine', 'learning', 'data' ] \n",
    "# 'data' is not in the word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23044683, -0.19492395], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(['machine', 'learning', 'data' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given a set of new keywords, find similar documents輸入一個詞或多個詞，找出幾篇相似的文章給你"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input: keywords\n",
    "\n",
    "Output: top n documents ranked by similarity\n",
    "\n",
    "Using model.docvecs.most_similar([ new_vector ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['machine', 'learning', 'job' ]\n",
    "\n",
    "# infer vector of keywords from the word2vec model (vector space)\n",
    "new_vector = model.infer_vector(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17611279, -0.05679075], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\4240576568.py:2: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.most_similar( positive= [new_vector], topn=5  )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc_2', 0.9265859127044678),\n",
       " ('doc_5', 0.2339228391647339),\n",
       " ('doc_0', -0.3956749439239502),\n",
       " ('doc_3', -0.7010857462882996),\n",
       " ('doc_1', -0.9204879403114319)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on the vector, find several nearby tags (item_id) \n",
    "model.docvecs.most_similar(positive = [new_vector], topn =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\659875514.py:5: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.most_similar(positive= [new_vector], topn =5 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc_2', 0.7138081789016724),\n",
       " ('doc_0', -0.01649193838238716),\n",
       " ('doc_5', -0.1535891443490982),\n",
       " ('doc_3', -0.37704989314079285),\n",
       " ('doc_4', -0.8784939646720886)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keywords can contain words which are not in the word index\n",
    "# infer_vecter() can deal with this, and it will not throw exception\n",
    "keywords = ['machine', 'learning', 'data' ]\n",
    "new_vector = model.infer_vector( keywords,  epochs = 20, alpha = 0.025)\n",
    "model.docvecs.most_similar(positive= [new_vector], topn =5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most similar documents輸入一篇文章編號，找出幾篇相似的文章給你"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docvecs.most_similar(positive=None, negative=None, topn=10, clip_start=0, clip_end=None, indexer=None)\n",
    "Find the top-N most similar docvecs from the training set. Positive docvecs contribute positively towards the similarity, negative docvecs negatively.\n",
    "\n",
    "This method computes cosine similarity between a simple mean of the projection weight vectors of the given docs. Docs may be specified as vectors, integer indexes of trained docvecs, or if the documents were originally presented with string tags, by the corresponding tags."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docvecs.similarity(d1, d2)\n",
    "Compute cosine similarity between two docvecs from the training set.\n",
    "\n",
    "TODO: Accept vectors of out-of-training-set docs, as if from inference.\n",
    "\n",
    "Parameters:\t\n",
    "d1 ({int, str}) – Doctag/index of document.\n",
    "d2 ({int, str}) – Doctag/index of document.\n",
    "Returns:\t\n",
    "The cosine similarity between the vectors of the two documents.\n",
    "\n",
    "Return type:\t\n",
    "float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given an item_id, find similar documents"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input: item_id (item_id in the word2vec model)\n",
    "\n",
    "Output: top n documents ranked by similarity\n",
    "\n",
    "Using model.docvecs.most_similar([item_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\345565659.py:4: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.most_similar(['doc_0'], topn=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc_3', 0.9322853088378906),\n",
       " ('doc_4', 0.49217653274536133),\n",
       " ('doc_1', 0.005333602894097567),\n",
       " ('doc_2', -0.7120180130004883),\n",
       " ('doc_5', -0.9854675531387329)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the top-N most similar documents\n",
    "\n",
    "# e.g., find similar documents for the first item_id\n",
    "model.docvecs.most_similar(['doc_0'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\347376770.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.most_similar('doc_0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc_3', 0.9322853088378906),\n",
       " ('doc_4', 0.49217653274536133),\n",
       " ('doc_1', 0.005333602894097567),\n",
       " ('doc_2', -0.7120180130004883),\n",
       " ('doc_5', -0.9854675531387329)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar('doc_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\1102969423.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.similarity('doc_0','doc_5')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.98546743"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.similarity('doc_0','doc_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find the most similar documents based on a set of documents輸入幾篇文章編號，找出幾篇相似的文章給你"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\1297811650.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.most_similar(['doc_0', 'doc_1'], topn = 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc_4', 0.9628377556800842),\n",
       " ('doc_3', 0.9160753488540649),\n",
       " ('doc_5', -0.5788949728012085)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar(['doc_0', 'doc_1'], topn = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\207899948.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.n_similarity( ['doc_0', 'doc_1'], ['doc_2'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.97078705"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.n_similarity( ['doc_0', 'doc_1'], ['doc_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42052\\3554709847.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.n_similarity( ['doc_0', 'doc_1'], ['doc_5'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.37033433"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.n_similarity( ['doc_0', 'doc_1'], ['doc_5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For more information about word embeddings, visit the following links:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wevi: word embedding visual inspector\n",
    "https://ronxin.github.io/wevi/\n",
    "\n",
    "\n",
    "in Chinese:\n",
    "\n",
    "(1) https://fgc.stpi.narl.org.tw/activity/videoDetail/4b1141305ddf5522015de5479f4701b1\n",
    "(2) https://medium.com/datamixcontent-lab/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90%E5%B8%AB%E8%87%AA%E5%AD%B8%E7%AD%86%E8%A8%98-%E6%A6%82%E5%BF%B5-%E5%AF%A6%E4%BD%9C%E7%AF%87-%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86%E5%85%A5%E9%96%80-%E4%B9%8B-word2vec-doc2vec-%E6%AF%94%E8%BC%83-c94dd0a407c7\n",
    "(3) https://medium.com/@ddoo8059/%E8%AE%80paper%E4%B9%8B%E5%BF%83%E5%BE%97-word2vec-%E8%88%87-doc2vec-5c8b8daa7f12\n",
    "\n",
    "\n",
    "in English:\n",
    "\n",
    "(1) https://www.guru99.com/word-embedding-word2vec.html\n",
    "(2) https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.76px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "df95319d8ce4e1d89f5365ae10992bc1f65da593082b1d264e8f529830ec2f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
